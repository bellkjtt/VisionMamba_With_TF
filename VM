{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[],"dockerImageVersionId":30762,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install -U zetascale","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow import keras\nimport numpy as np\nfrom tensorflow.keras import layers\n\ndef load_and_preprocess_mnist():\n    (x_train, y_train), (x_test, y_test) = keras.datasets.mnist.load_data()\n    \n    x_train = x_train.astype(\"float32\") / 255\n    x_test = x_test.astype(\"float32\") / 255\n    x_train = np.expand_dims(x_train, -1)\n    x_test = np.expand_dims(x_test, -1)\n    \n    y_train = keras.utils.to_categorical(y_train, 10)\n    y_test = keras.utils.to_categorical(y_test, 10)\n    \n    return (x_train, y_train), (x_test, y_test)\n\ndef train_and_evaluate_model(model, x_train, y_train, x_test, y_test, epochs=10, batch_size=128):\n    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n    \n    history = model.fit(\n        x_train, y_train,\n        validation_data=(x_test, y_test),\n        epochs=epochs,\n        batch_size=batch_size\n    )\n    \n    test_loss, test_accuracy = model.evaluate(x_test, y_test)\n    print(f\"Test accuracy: {test_accuracy:.4f}\")\n    \n    return history","metadata":{"execution":{"iopub.status.busy":"2024-09-23T11:04:04.272874Z","iopub.execute_input":"2024-09-23T11:04:04.273274Z","iopub.status.idle":"2024-09-23T11:04:04.283010Z","shell.execute_reply.started":"2024-09-23T11:04:04.273233Z","shell.execute_reply":"2024-09-23T11:04:04.281977Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow.keras import layers\n\ndef selective_scan(x, delta, A, B, C, D):\n    \"\"\"\n    Perform selective scan operation on the input tensor.\n    \"\"\"\n\n    L = tf.shape(x)[1]\n\n    deltaA = tf.exp(tf.expand_dims(delta, -1) * A)  # (B, L, ED, N)\n    deltaB = tf.expand_dims(delta, -1) * tf.expand_dims(B, 2)  # (B, L, ED, N)\n    \n    print(x,'들어가는 X')\n    print(deltaA,'A번')\n    print(deltaB,'B번')\n    BX = deltaB * tf.expand_dims(x, -1)  # (B, L, ED, N)\n\n    hs = pscan(deltaA, BX)\n\n    y = tf.squeeze(hs @ tf.expand_dims(C, -1), axis=-1)  # (B, L, ED, 1)\n\n    y = y + D * x\n\n    return y\n\n\ndef selective_scan_seq(x, delta, A, B, C, D, dim_inner, d_state):\n    \"\"\"\n    Perform selective scan sequence operation on the input tensor.\n    \"\"\"\n    L = tf.shape(x)[1]\n\n    deltaA = tf.exp(tf.expand_dims(delta, -1) * A)  # (B, L, ED, N)\n    deltaB = tf.expand_dims(delta, -1) * tf.expand_dims(B, 2)  # (B, L, ED, N)\n\n    BX = deltaB * tf.expand_dims(x, -1)  # (B, L, ED, N)\n\n    h = tf.zeros([tf.shape(x)[0], dim_inner, d_state], dtype=tf.float32)  # (B, ED, N)\n    hs = []\n\n    for t in range(L):\n        h = deltaA[:, t] * h + BX[:, t]\n        hs.append(h)\n\n    hs = tf.stack(hs, axis=1)  # (B, L, ED, N)\n\n    y = tf.squeeze(hs @ tf.expand_dims(C, -1), axis=-1)  # (B, L, ED, 1)\n\n    y = y + D * x\n\n    return y\n","metadata":{"execution":{"iopub.status.busy":"2024-09-23T11:04:05.237786Z","iopub.execute_input":"2024-09-23T11:04:05.238171Z","iopub.status.idle":"2024-09-23T11:04:05.251066Z","shell.execute_reply.started":"2024-09-23T11:04:05.238133Z","shell.execute_reply":"2024-09-23T11:04:05.250081Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"class SSM(layers.Layer):\n    def __init__(self, in_features, dt_rank, dim_inner, d_state):\n        super(SSM, self).__init__()\n        self.dt_rank = dt_rank\n        self.dim_inner = dim_inner\n        self.d_state = d_state\n\n        # Linear layers using Dense\n        self.deltaBC_layer = layers.Dense(dt_rank + 2 * d_state, use_bias=False)\n        self.dt_proj_layer = layers.Dense(dim_inner, use_bias=True)\n\n        # Parameters A_log and D using tf.Variable\n        self.A_log = tf.Variable(\n            tf.math.log(\n                tf.range(1, d_state + 1, dtype=tf.float32)[tf.newaxis, :]\n            ) * tf.ones([dim_inner, d_state], dtype=tf.float32)\n        )\n        self.D = tf.Variable(tf.ones([dim_inner], dtype=tf.float32))\n\n    def call(self, x, pscan=True):\n        A = -tf.exp(self.A_log)\n        D = self.D\n\n        deltaBC = self.deltaBC_layer(x)\n        delta, B, C = tf.split(deltaBC, [self.dt_rank, self.d_state, self.d_state], axis=-1)\n        delta = tf.nn.softplus(self.dt_proj_layer(delta))\n\n        if pscan:\n            y = selective_scan(x, delta, A, B, C, D)\n        else:\n            y = selective_scan_seq(x, delta, A, B, C, D, self.dim_inner, self.d_state)\n\n        return y\n","metadata":{"execution":{"iopub.status.busy":"2024-09-23T11:04:05.606577Z","iopub.execute_input":"2024-09-23T11:04:05.606986Z","iopub.status.idle":"2024-09-23T11:04:05.617642Z","shell.execute_reply.started":"2024-09-23T11:04:05.606946Z","shell.execute_reply":"2024-09-23T11:04:05.616646Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow.keras import layers, Model\nfrom tensorflow.keras.layers import LayerNormalization, Conv1D, Dense, Activation\n# from zeta.nn import SSM\n# Keras에서 einops 대신 tf.reshape이나 tf.transpose 사용 가능\n\ndef output_head(dim: int, num_classes: int):\n    \"\"\"\n    Creates a head for the output layer of a model.\n    Args:\n        dim (int): The input dimension of the head.\n        num_classes (int): The number of output classes.\n    Returns:\n        keras.Sequential: The output head module.\n    \"\"\"\n    return tf.keras.Sequential([\n        layers.GlobalAveragePooling1D(),\n        layers.LayerNormalization(),\n        layers.Dense(num_classes, activation='softmax')  # 최종 분류 레이어\n    ])\n\nclass VisionEncoderMambaBlock(tf.keras.layers.Layer):\n    def __init__(self, dim: int, dt_rank: int, dim_inner: int, d_state: int):\n        super().__init__()\n        self.dim = dim\n        self.dt_rank = dt_rank\n        self.dim_inner = dim_inner\n        self.d_state = d_state\n\n        # Keras Conv1D 레이어 사용\n        self.forward_conv1d = Conv1D(filters=dim, kernel_size=1, padding='same')\n        self.backward_conv1d = Conv1D(filters=dim, kernel_size=1, padding='same')\n\n        # LayerNormalization\n        self.norm = LayerNormalization()\n        self.silu = Activation('swish')  # Keras에서 SiLU = swish\n        self.ssm = SSM(dim, dt_rank, dim_inner, d_state)  # SSM 레이어 추가\n\n        # Linear layer for z and x\n        self.proj = Dense(dim)\n\n    def call(self, x):\n        skip = x\n        x = self.norm(x)  # Normalization\n\n        # Linear projections for z1 and x\n        z1 = self.proj(x)\n        x = self.proj(x)\n\n        # Forward and backward Conv1D\n        x1 = self.process_direction(x, self.forward_conv1d)\n        x2 = self.process_direction(x, self.backward_conv1d)\n\n        # SiLU activation\n        z = self.silu(z1)\n\n        # Matmul operation\n        x1 = x1 * z\n        x2 = x2 * z\n\n        # Residual connection\n        return x1 + x2 + skip\n\n    def process_direction(self, x, conv1d):\n        x = tf.transpose(x, perm=[0, 2, 1])  # (batch, seq_len, dim) -> (batch, dim, seq_len)\n        x = tf.nn.softplus(conv1d(x))  # Conv1D 적용 후 softplus\n        x = tf.transpose(x, perm=[0, 2, 1])  # 다시 원래 shape로 복원\n        x = self.ssm(x)  # SSM 적용\n        return x\n\nclass Vim(tf.keras.Model):\n    def __init__(self, dim: int, dt_rank: int = 32, dim_inner: int = 128, d_state: int = 128, \n                 num_classes: int = None, image_size: int = 224, patch_size: int = 16, \n                 channels: int = 3, dropout: float = 0.1, depth: int = 12):\n        super().__init__()\n        self.dim = dim\n        self.dt_rank = dt_rank\n        self.dim_inner = dim_inner\n        self.d_state = d_state\n        self.num_classes = num_classes\n\n        patch_dim = channels * patch_size * patch_size\n\n        # Patch embedding\n        self.to_patch_embedding = tf.keras.Sequential([\n            layers.Conv2D(filters=dim, kernel_size=patch_size, strides=patch_size, padding='same'),\n            layers.Reshape((-1, dim))  # (batch, height, width, channels) -> (batch, num_patches, dim)\n        ])\n\n        self.cls_token = self.add_weight(shape=(1, 1, dim), initializer='random_normal', trainable=True)\n        self.dropout = layers.Dropout(dropout)\n\n        # Encoder blocks\n        self.layers_list = []\n        for _ in range(depth):\n            self.layers_list.append(VisionEncoderMambaBlock(dim=dim, dt_rank=dt_rank, dim_inner=dim_inner, d_state=d_state))\n\n        # Output head\n        self.output_head = output_head(dim, num_classes)\n\n    def call(self, x):\n        x = self.to_patch_embedding(x)\n\n        # Add class token\n        cls_tokens = tf.repeat(self.cls_token, repeats=tf.shape(x)[0], axis=0)\n        x = tf.concat([cls_tokens, x], axis=1)\n\n        x = self.dropout(x)\n\n        # Forward through all layers\n        for layer in self.layers_list:\n            x = layer(x)\n\n        # Output head\n        return self.output_head(x)\n\n# Model usage example\nmodel = Vim(dim=256, num_classes=10)","metadata":{"execution":{"iopub.status.busy":"2024-09-23T11:04:06.069439Z","iopub.execute_input":"2024-09-23T11:04:06.070267Z","iopub.status.idle":"2024-09-23T11:04:06.240411Z","shell.execute_reply.started":"2024-09-23T11:04:06.070225Z","shell.execute_reply":"2024-09-23T11:04:06.239453Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"model.summary()","metadata":{"execution":{"iopub.status.busy":"2024-09-23T11:04:06.850819Z","iopub.execute_input":"2024-09-23T11:04:06.851797Z","iopub.status.idle":"2024-09-23T11:04:06.878270Z","shell.execute_reply.started":"2024-09-23T11:04:06.851751Z","shell.execute_reply":"2024-09-23T11:04:06.877374Z"},"trusted":true},"execution_count":22,"outputs":[{"output_type":"display_data","data":{"text/plain":"\u001b[1mModel: \"vim_4\"\u001b[0m\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"vim_4\"</span>\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n│ sequential_8 (\u001b[38;5;33mSequential\u001b[0m)       │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dropout_4 (\u001b[38;5;33mDropout\u001b[0m)             │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ vision_encoder_mamba_block_48   │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n│ (\u001b[38;5;33mVisionEncoderMambaBlock\u001b[0m)       │                        │               │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ vision_encoder_mamba_block_49   │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n│ (\u001b[38;5;33mVisionEncoderMambaBlock\u001b[0m)       │                        │               │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ vision_encoder_mamba_block_50   │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n│ (\u001b[38;5;33mVisionEncoderMambaBlock\u001b[0m)       │                        │               │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ vision_encoder_mamba_block_51   │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n│ (\u001b[38;5;33mVisionEncoderMambaBlock\u001b[0m)       │                        │               │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ vision_encoder_mamba_block_52   │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n│ (\u001b[38;5;33mVisionEncoderMambaBlock\u001b[0m)       │                        │               │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ vision_encoder_mamba_block_53   │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n│ (\u001b[38;5;33mVisionEncoderMambaBlock\u001b[0m)       │                        │               │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ vision_encoder_mamba_block_54   │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n│ (\u001b[38;5;33mVisionEncoderMambaBlock\u001b[0m)       │                        │               │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ vision_encoder_mamba_block_55   │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n│ (\u001b[38;5;33mVisionEncoderMambaBlock\u001b[0m)       │                        │               │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ vision_encoder_mamba_block_56   │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n│ (\u001b[38;5;33mVisionEncoderMambaBlock\u001b[0m)       │                        │               │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ vision_encoder_mamba_block_57   │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n│ (\u001b[38;5;33mVisionEncoderMambaBlock\u001b[0m)       │                        │               │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ vision_encoder_mamba_block_58   │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n│ (\u001b[38;5;33mVisionEncoderMambaBlock\u001b[0m)       │                        │               │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ vision_encoder_mamba_block_59   │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n│ (\u001b[38;5;33mVisionEncoderMambaBlock\u001b[0m)       │                        │               │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ sequential_9 (\u001b[38;5;33mSequential\u001b[0m)       │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n└─────────────────────────────────┴────────────────────────┴───────────────┘\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n│ sequential_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Sequential</span>)       │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dropout_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ vision_encoder_mamba_block_48   │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">VisionEncoderMambaBlock</span>)       │                        │               │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ vision_encoder_mamba_block_49   │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">VisionEncoderMambaBlock</span>)       │                        │               │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ vision_encoder_mamba_block_50   │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">VisionEncoderMambaBlock</span>)       │                        │               │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ vision_encoder_mamba_block_51   │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">VisionEncoderMambaBlock</span>)       │                        │               │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ vision_encoder_mamba_block_52   │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">VisionEncoderMambaBlock</span>)       │                        │               │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ vision_encoder_mamba_block_53   │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">VisionEncoderMambaBlock</span>)       │                        │               │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ vision_encoder_mamba_block_54   │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">VisionEncoderMambaBlock</span>)       │                        │               │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ vision_encoder_mamba_block_55   │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">VisionEncoderMambaBlock</span>)       │                        │               │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ vision_encoder_mamba_block_56   │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">VisionEncoderMambaBlock</span>)       │                        │               │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ vision_encoder_mamba_block_57   │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">VisionEncoderMambaBlock</span>)       │                        │               │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ vision_encoder_mamba_block_58   │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">VisionEncoderMambaBlock</span>)       │                        │               │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ vision_encoder_mamba_block_59   │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">VisionEncoderMambaBlock</span>)       │                        │               │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ sequential_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Sequential</span>)       │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n└─────────────────────────────────┴────────────────────────┴───────────────┘\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Total params: \u001b[0m\u001b[38;5;34m256\u001b[0m (1.00 KB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> (1.00 KB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m256\u001b[0m (1.00 KB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> (1.00 KB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n</pre>\n"},"metadata":{}}]},{"cell_type":"code","source":"if __name__ == \"__main__\":\n    (x_train, y_train), (x_test, y_test) = load_and_preprocess_mnist()\n    \n    model = Vim(dim=256, num_classes=10)\n    model.summary()\n    \n    history = train_and_evaluate_model(model, x_train, y_train, x_test, y_test)\n    \n    # 학습 곡선 플로팅 (옵션)\n    import matplotlib.pyplot as plt\n    \n    plt.figure(figsize=(12, 4))\n    plt.subplot(1, 2, 1)\n    plt.plot(history.history['accuracy'], label='Train Accuracy')\n    plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n    plt.title('Model Accuracy')\n    plt.xlabel('Epoch')\n    plt.ylabel('Accuracy')\n    plt.legend()\n    \n    plt.subplot(1, 2, 2)\n    plt.plot(history.history['loss'], label='Train Loss')\n    plt.plot(history.history['val_loss'], label='Validation Loss')\n    plt.title('Model Loss')\n    plt.xlabel('Epoch')\n    plt.ylabel('Loss')\n    plt.legend()\n    \n    plt.tight_layout()\n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2024-09-23T11:04:07.450475Z","iopub.execute_input":"2024-09-23T11:04:07.450857Z","iopub.status.idle":"2024-09-23T11:04:09.291878Z","shell.execute_reply.started":"2024-09-23T11:04:07.450816Z","shell.execute_reply":"2024-09-23T11:04:09.290468Z"},"trusted":true},"execution_count":23,"outputs":[{"output_type":"display_data","data":{"text/plain":"\u001b[1mModel: \"vim_5\"\u001b[0m\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"vim_5\"</span>\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n│ sequential_10 (\u001b[38;5;33mSequential\u001b[0m)      │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dropout_5 (\u001b[38;5;33mDropout\u001b[0m)             │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ vision_encoder_mamba_block_60   │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n│ (\u001b[38;5;33mVisionEncoderMambaBlock\u001b[0m)       │                        │               │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ vision_encoder_mamba_block_61   │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n│ (\u001b[38;5;33mVisionEncoderMambaBlock\u001b[0m)       │                        │               │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ vision_encoder_mamba_block_62   │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n│ (\u001b[38;5;33mVisionEncoderMambaBlock\u001b[0m)       │                        │               │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ vision_encoder_mamba_block_63   │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n│ (\u001b[38;5;33mVisionEncoderMambaBlock\u001b[0m)       │                        │               │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ vision_encoder_mamba_block_64   │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n│ (\u001b[38;5;33mVisionEncoderMambaBlock\u001b[0m)       │                        │               │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ vision_encoder_mamba_block_65   │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n│ (\u001b[38;5;33mVisionEncoderMambaBlock\u001b[0m)       │                        │               │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ vision_encoder_mamba_block_66   │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n│ (\u001b[38;5;33mVisionEncoderMambaBlock\u001b[0m)       │                        │               │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ vision_encoder_mamba_block_67   │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n│ (\u001b[38;5;33mVisionEncoderMambaBlock\u001b[0m)       │                        │               │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ vision_encoder_mamba_block_68   │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n│ (\u001b[38;5;33mVisionEncoderMambaBlock\u001b[0m)       │                        │               │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ vision_encoder_mamba_block_69   │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n│ (\u001b[38;5;33mVisionEncoderMambaBlock\u001b[0m)       │                        │               │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ vision_encoder_mamba_block_70   │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n│ (\u001b[38;5;33mVisionEncoderMambaBlock\u001b[0m)       │                        │               │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ vision_encoder_mamba_block_71   │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n│ (\u001b[38;5;33mVisionEncoderMambaBlock\u001b[0m)       │                        │               │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ sequential_11 (\u001b[38;5;33mSequential\u001b[0m)      │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n└─────────────────────────────────┴────────────────────────┴───────────────┘\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n│ sequential_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Sequential</span>)      │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dropout_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ vision_encoder_mamba_block_60   │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">VisionEncoderMambaBlock</span>)       │                        │               │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ vision_encoder_mamba_block_61   │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">VisionEncoderMambaBlock</span>)       │                        │               │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ vision_encoder_mamba_block_62   │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">VisionEncoderMambaBlock</span>)       │                        │               │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ vision_encoder_mamba_block_63   │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">VisionEncoderMambaBlock</span>)       │                        │               │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ vision_encoder_mamba_block_64   │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">VisionEncoderMambaBlock</span>)       │                        │               │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ vision_encoder_mamba_block_65   │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">VisionEncoderMambaBlock</span>)       │                        │               │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ vision_encoder_mamba_block_66   │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">VisionEncoderMambaBlock</span>)       │                        │               │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ vision_encoder_mamba_block_67   │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">VisionEncoderMambaBlock</span>)       │                        │               │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ vision_encoder_mamba_block_68   │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">VisionEncoderMambaBlock</span>)       │                        │               │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ vision_encoder_mamba_block_69   │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">VisionEncoderMambaBlock</span>)       │                        │               │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ vision_encoder_mamba_block_70   │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">VisionEncoderMambaBlock</span>)       │                        │               │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ vision_encoder_mamba_block_71   │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">VisionEncoderMambaBlock</span>)       │                        │               │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ sequential_11 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Sequential</span>)      │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n└─────────────────────────────────┴────────────────────────┴───────────────┘\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Total params: \u001b[0m\u001b[38;5;34m256\u001b[0m (1.00 KB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> (1.00 KB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m256\u001b[0m (1.00 KB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> (1.00 KB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n</pre>\n"},"metadata":{}},{"name":"stdout","text":"Epoch 1/10\nTensor(\"transpose_1:0\", shape=(None, 256, 256), dtype=float32) 들어가는 X\nTensor(\"Exp_1:0\", shape=(None, 256, 128, 128), dtype=float32) A번\nTensor(\"mul_1:0\", shape=(None, 256, 128, 128), dtype=float32) B번\nTensor(\"transpose_1:0\", shape=(None, 256, 256), dtype=float32) 들어가는 X\nTensor(\"ssm_60_1/Exp_1:0\", shape=(None, 256, 128, 128), dtype=float32) A번\nTensor(\"ssm_60_1/mul_1:0\", shape=(None, 256, 128, 128), dtype=float32) B번\nTensor(\"vision_encoder_mamba_block_60_1/transpose_1:0\", shape=(None, 256, 256), dtype=float32) 들어가는 X\nTensor(\"vision_encoder_mamba_block_60_1/ssm_60_1/Exp_1:0\", shape=(None, 256, 128, 128), dtype=float32) A번\nTensor(\"vision_encoder_mamba_block_60_1/ssm_60_1/mul_1:0\", shape=(None, 256, 128, 128), dtype=float32) B번\nTensor(\"transpose_1:0\", shape=(None, 256, 256), dtype=float32) 들어가는 X\nTensor(\"ssm_60_1/Exp_1:0\", shape=(None, 256, 128, 128), dtype=float32) A번\nTensor(\"ssm_60_1/mul_1:0\", shape=(None, 256, 128, 128), dtype=float32) B번\nTensor(\"vim_5_1/vision_encoder_mamba_block_60_1/transpose_1:0\", shape=(None, 256, 256), dtype=float32) 들어가는 X\nTensor(\"vim_5_1/vision_encoder_mamba_block_60_1/ssm_60_1/Exp_1:0\", shape=(None, 256, 128, 128), dtype=float32) A번\nTensor(\"vim_5_1/vision_encoder_mamba_block_60_1/ssm_60_1/mul_1:0\", shape=(None, 256, 128, 128), dtype=float32) B번\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","Cell \u001b[0;32mIn[23], line 7\u001b[0m\n\u001b[1;32m      4\u001b[0m model \u001b[38;5;241m=\u001b[39m Vim(dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m256\u001b[39m, num_classes\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m)\n\u001b[1;32m      5\u001b[0m model\u001b[38;5;241m.\u001b[39msummary()\n\u001b[0;32m----> 7\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_and_evaluate_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_test\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m# 학습 곡선 플로팅 (옵션)\u001b[39;00m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n","Cell \u001b[0;32mIn[18], line 22\u001b[0m, in \u001b[0;36mtrain_and_evaluate_model\u001b[0;34m(model, x_train, y_train, x_test, y_test, epochs, batch_size)\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtrain_and_evaluate_model\u001b[39m(model, x_train, y_train, x_test, y_test, epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m, batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m128\u001b[39m):\n\u001b[1;32m     20\u001b[0m     model\u001b[38;5;241m.\u001b[39mcompile(optimizer\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124madam\u001b[39m\u001b[38;5;124m'\u001b[39m, loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcategorical_crossentropy\u001b[39m\u001b[38;5;124m'\u001b[39m, metrics\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m---> 22\u001b[0m     history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     23\u001b[0m \u001b[43m        \u001b[49m\u001b[43mx_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     24\u001b[0m \u001b[43m        \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mx_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_test\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     25\u001b[0m \u001b[43m        \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     26\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\n\u001b[1;32m     27\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     29\u001b[0m     test_loss, test_accuracy \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mevaluate(x_test, y_test)\n\u001b[1;32m     30\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTest accuracy: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtest_accuracy\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py:122\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m    120\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m    121\u001b[0m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m--> 122\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    123\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    124\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n","Cell \u001b[0;32mIn[21], line 112\u001b[0m, in \u001b[0;36mVim.call\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    110\u001b[0m \u001b[38;5;66;03m# Forward through all layers\u001b[39;00m\n\u001b[1;32m    111\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m layer \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayers_list:\n\u001b[0;32m--> 112\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[43mlayer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    114\u001b[0m \u001b[38;5;66;03m# Output head\u001b[39;00m\n\u001b[1;32m    115\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutput_head(x)\n","Cell \u001b[0;32mIn[21], line 51\u001b[0m, in \u001b[0;36mVisionEncoderMambaBlock.call\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     48\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mproj(x)\n\u001b[1;32m     50\u001b[0m \u001b[38;5;66;03m# Forward and backward Conv1D\u001b[39;00m\n\u001b[0;32m---> 51\u001b[0m x1 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprocess_direction\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward_conv1d\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     52\u001b[0m x2 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprocess_direction(x, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbackward_conv1d)\n\u001b[1;32m     54\u001b[0m \u001b[38;5;66;03m# SiLU activation\u001b[39;00m\n","Cell \u001b[0;32mIn[21], line 68\u001b[0m, in \u001b[0;36mVisionEncoderMambaBlock.process_direction\u001b[0;34m(self, x, conv1d)\u001b[0m\n\u001b[1;32m     66\u001b[0m x \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39msoftplus(conv1d(x))  \u001b[38;5;66;03m# Conv1D 적용 후 softplus\u001b[39;00m\n\u001b[1;32m     67\u001b[0m x \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mtranspose(x, perm\u001b[38;5;241m=\u001b[39m[\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m1\u001b[39m])  \u001b[38;5;66;03m# 다시 원래 shape로 복원\u001b[39;00m\n\u001b[0;32m---> 68\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mssm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# SSM 적용\u001b[39;00m\n\u001b[1;32m     69\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m x\n","Cell \u001b[0;32mIn[20], line 29\u001b[0m, in \u001b[0;36mSSM.call\u001b[0;34m(self, x, pscan)\u001b[0m\n\u001b[1;32m     26\u001b[0m delta \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39msoftplus(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdt_proj_layer(delta))\n\u001b[1;32m     28\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m pscan:\n\u001b[0;32m---> 29\u001b[0m     y \u001b[38;5;241m=\u001b[39m \u001b[43mselective_scan\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdelta\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mA\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mB\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mC\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mD\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     30\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     31\u001b[0m     y \u001b[38;5;241m=\u001b[39m selective_scan_seq(x, delta, A, B, C, D, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdim_inner, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39md_state)\n","Cell \u001b[0;32mIn[19], line 17\u001b[0m, in \u001b[0;36mselective_scan\u001b[0;34m(x, delta, A, B, C, D)\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28mprint\u001b[39m(deltaA,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mA번\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28mprint\u001b[39m(deltaB,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mB번\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m---> 17\u001b[0m BX \u001b[38;5;241m=\u001b[39m \u001b[43mdeltaB\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexpand_dims\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# (B, L, ED, N)\u001b[39;00m\n\u001b[1;32m     19\u001b[0m hs \u001b[38;5;241m=\u001b[39m pscan(deltaA, BX)\n\u001b[1;32m     21\u001b[0m y \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39msqueeze(hs \u001b[38;5;241m@\u001b[39m tf\u001b[38;5;241m.\u001b[39mexpand_dims(C, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m), axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)  \u001b[38;5;66;03m# (B, L, ED, 1)\u001b[39;00m\n","\u001b[0;31mValueError\u001b[0m: Exception encountered when calling SSM.call().\n\n\u001b[1mDimensions must be equal, but are 128 and 256 for '{{node vim_5_1/vision_encoder_mamba_block_60_1/ssm_60_1/mul_2}} = Mul[T=DT_FLOAT](vim_5_1/vision_encoder_mamba_block_60_1/ssm_60_1/mul_1, vim_5_1/vision_encoder_mamba_block_60_1/ssm_60_1/ExpandDims_3)' with input shapes: [?,256,128,128], [?,256,256,1].\u001b[0m\n\nArguments received by SSM.call():\n  • x=tf.Tensor(shape=(None, 256, 256), dtype=float32)\n  • pscan=True"],"ename":"ValueError","evalue":"Exception encountered when calling SSM.call().\n\n\u001b[1mDimensions must be equal, but are 128 and 256 for '{{node vim_5_1/vision_encoder_mamba_block_60_1/ssm_60_1/mul_2}} = Mul[T=DT_FLOAT](vim_5_1/vision_encoder_mamba_block_60_1/ssm_60_1/mul_1, vim_5_1/vision_encoder_mamba_block_60_1/ssm_60_1/ExpandDims_3)' with input shapes: [?,256,128,128], [?,256,256,1].\u001b[0m\n\nArguments received by SSM.call():\n  • x=tf.Tensor(shape=(None, 256, 256), dtype=float32)\n  • pscan=True","output_type":"error"}]},{"cell_type":"code","source":"!pip install -U zetascale","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}